{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6429f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel, TimesformerForVideoClassification, AutoImageProcessor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652785e",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537256f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         title_overview  \\\n",
      "0     Good Deeds: For all his life, wealthy business...   \n",
      "1     We Summon the Darkness: Three best friends att...   \n",
      "2     Personal Effects: Walter is a rising star in t...   \n",
      "3     Ant-Man and the Wasp: Just when his time under...   \n",
      "4     Bombshell: Bombshell is a revealing look insid...   \n",
      "...                                                 ...   \n",
      "3478  Poms: After moving to a retirement community, ...   \n",
      "3479  The Vault: Two estranged sisters are forced to...   \n",
      "3480  The Secrets We Keep: In post-World War II Amer...   \n",
      "3481  Cats & Dogs: The Revenge of Kitty Galore: The ...   \n",
      "3482  Deadpool 2: Wisecracking mercenary Deadpool ba...   \n",
      "\n",
      "                                                   tags    revenue  \n",
      "0     \"Tyler Perry,Thandie Newton,Brian White,Rebecc...   35579177  \n",
      "1     \"we summon the darkness,we summon the darkness...     190760  \n",
      "2                                                           471645  \n",
      "3     \"marvel,comics,comic books,nerd,geek,superhero...  622674139  \n",
      "4     \"bombshell,lionsgate,bombshell movie,bombshell...   61404394  \n",
      "...                                                 ...        ...  \n",
      "3478  \"Poms,Poms trailer,Poms movie,movie,movies,tra...    8600192  \n",
      "3479  \"The Vault,James Franco,Taryn Manning,Thriller...       5728  \n",
      "3480  \"bleecker street,bleecker street media,bleecke...     615233  \n",
      "3481  \"cats & dogs 2,cats & dogs 2 trailer,cats & do...  112483764  \n",
      "3482  \"Trailer,Deadpool,20th Century Fox (Production...  785896632  \n",
      "\n",
      "[3483 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def build_tag_vocab(tag_lists, min_freq=1):\n",
    "    tag_freq = defaultdict(int)\n",
    "    for tags in tag_lists:\n",
    "        for tag in tags:\n",
    "            tag_freq[tag.lower()] += 1\n",
    "\n",
    "    vocab = {'[PAD]': 0, '[UNK]': 1}\n",
    "    for tag, freq in tag_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[tag] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "df_train = pd.read_csv('movie_data_train.csv')\n",
    "\n",
    "df_train['title_overview'] = df_train['original_title'] + ': ' + df_train['overview']\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    'title_overview': df_train['title_overview'],\n",
    "    'tags': df_train['tags'].fillna(''),\n",
    "    'revenue': df_train['revenue']\n",
    "})\n",
    "\n",
    "df_test = pd.read_csv('movie_data_test.csv')\n",
    "\n",
    "df_test['title_overview'] = df_test['original_title'] + ': ' + df_test['overview']\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'title_overview': df_test['title_overview'],\n",
    "    'tags': df_test['tags'].fillna(''),\n",
    "    'revenue': df_test['revenue']\n",
    "})\n",
    "\n",
    "df_train['revenue'] = np.log1p(df_train['revenue'])\n",
    "df_test['revenue'] = np.log1p(df_test['revenue'])\n",
    "\n",
    "df_train['tags'] = df_train['tags'].apply(lambda x: [tag.strip().lower() for tag in x.split(',') if tag.strip()])\n",
    "df_test['tags'] = df_test['tags'].apply(lambda x: [tag.strip().lower() for tag in x.split(',') if tag.strip()])\n",
    "\n",
    "train_texts = df_train['title_overview'].tolist()\n",
    "train_tags = df_train['tags'].tolist()\n",
    "train_targets = df_train['revenue'].tolist()\n",
    "\n",
    "test_texts = df_test['title_overview'].tolist()\n",
    "test_tags = df_test['tags'].tolist()\n",
    "test_targets = df_test['revenue'].tolist()\n",
    "\n",
    "tag_vocab = build_tag_vocab(train_tags + test_tags)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b25f9",
   "metadata": {},
   "source": [
    "## Prepare Title/Overview + Tag 2 Tower BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a96b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagCNNEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=300, num_filters=128, kernel_sizes=(2, 3, 4), dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(embed_dim, num_filters, k) for k in kernel_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x).transpose(1, 2)\n",
    "        conv_outs = [torch.relu(conv(embedded)).max(dim=2)[0] for conv in self.convs]\n",
    "        out = torch.cat(conv_outs, dim=1)\n",
    "        return self.dropout(out)\n",
    "\n",
    "class BERTWithTagCNNRegressor(nn.Module):\n",
    "    def __init__(self, tag_vocab_size, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.tag_encoder = TagCNNEncoder(tag_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size + 384, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_input_ids, text_attention_mask, tag_token_ids):\n",
    "\n",
    "        bert_output = self.bert(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
    "        text_cls = bert_output.pooler_output  \n",
    "\n",
    "        tag_feat = self.tag_encoder(tag_token_ids)\n",
    "\n",
    "        fused = torch.cat([text_cls, tag_feat], dim=1)\n",
    "        return self.regressor(self.dropout(fused))\n",
    "    \n",
    "class MovieDatasetWithTags(nn.Module):\n",
    "    def __init__(self, texts, tags, targets, tokenizer, tag_vocab, max_text_len=256, max_tag_len=20):\n",
    "        self.texts = texts\n",
    "        self.tags = tags\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tag_vocab = tag_vocab\n",
    "        self.max_text_len = max_text_len\n",
    "        self.max_tag_len = max_tag_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def encode_tags(self, tag_list):\n",
    "        tag_ids = [self.tag_vocab.get(tag.lower(), self.tag_vocab['[UNK]']) for tag in tag_list]\n",
    "        tag_ids = tag_ids[:self.max_tag_len]\n",
    "        tag_ids += [self.tag_vocab['[PAD]']] * (self.max_tag_len - len(tag_ids))\n",
    "        return torch.tensor(tag_ids, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        tags = self.tags[idx]\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "\n",
    "        text_enc = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_text_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        tag_tensor = self.encode_tags(tags)\n",
    "\n",
    "        return {\n",
    "            'input_ids': text_enc['input_ids'].squeeze(0),\n",
    "            'attention_mask': text_enc['attention_mask'].squeeze(0),\n",
    "            'tags': tag_tensor,\n",
    "            'target': target\n",
    "        }\n",
    "\n",
    "train_texts_split, val_texts, train_tags_split, val_tags, train_targets_split, val_targets = train_test_split(\n",
    "    train_texts, train_tags, train_targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = MovieDatasetWithTags(train_texts_split, train_tags_split, train_targets_split, tokenizer, tag_vocab)\n",
    "val_dataset = MovieDatasetWithTags(val_texts, val_tags, val_targets, tokenizer, tag_vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "test_dataset = MovieDatasetWithTags(test_texts, test_tags, test_targets, tokenizer, tag_vocab)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8530e",
   "metadata": {},
   "source": [
    "## Get Predictions of 2 Tower BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5dd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTWithTagCNNRegressor(tag_vocab_size=len(tag_vocab)).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "checkpoint = torch.load('models/title_overview_two_tower_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "title_train_predictions = []\n",
    "train_actuals = []\n",
    "title_val_predictions = []\n",
    "val_actuals = []\n",
    "title_test_predictions = []\n",
    "test_actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tags = batch['tags'].to(device)\n",
    "        targets = batch['target'].cpu().numpy()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, tags).squeeze().cpu().numpy()\n",
    "        \n",
    "        title_train_predictions.extend(outputs)\n",
    "        train_actuals.extend(targets)\n",
    "\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tags = batch['tags'].to(device)\n",
    "        targets = batch['target'].cpu().numpy()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, tags).squeeze().cpu().numpy()\n",
    "        \n",
    "        title_val_predictions.extend(outputs)\n",
    "        val_actuals.extend(targets)\n",
    "\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tags = batch['tags'].to(device)\n",
    "        targets = batch['target'].cpu().numpy()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, tags).squeeze().cpu().numpy()\n",
    "\n",
    "        title_test_predictions.extend(outputs)\n",
    "        test_actuals.extend(targets)\n",
    "        \n",
    "        \n",
    "\n",
    "title_train_preds = np.expm1(title_train_predictions)\n",
    "train_actuals = np.expm1(train_actuals)\n",
    "title_val_preds = np.expm1(title_val_predictions)\n",
    "val_actuals = np.expm1(val_actuals)\n",
    "title_test_preds = np.expm1(title_test_predictions)\n",
    "test_actuals = np.expm1(test_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcaa44a",
   "metadata": {},
   "source": [
    "## Setting Up Visual Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e5a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiImageDataset(Dataset):\n",
    "    def __init__(self, df, poster_dir, backdrop_dir, thumbnail_dir, transform):\n",
    "        self.df = df\n",
    "        self.poster_dir = poster_dir\n",
    "        self.backdrop_dir = backdrop_dir\n",
    "        self.thumbnail_dir = thumbnail_dir\n",
    "        self.transform = transform\n",
    "        self.valid_ids = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            movie_id = str(int(row['id']))\n",
    "            if all(os.path.exists(os.path.join(d, f\"{movie_id}.jpg\")) for d in [poster_dir, backdrop_dir, thumbnail_dir]):\n",
    "                self.valid_ids.append(idx)\n",
    "            else:\n",
    "                self.valid_ids.append(-1)                \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.valid_ids[idx] == -1:\n",
    "            return {\n",
    "                \"poster\": torch.zeros(3, 224, 224),\n",
    "                \"backdrop\": torch.zeros(3, 224, 224),\n",
    "                \"thumbnail\": torch.zeros(3, 224, 224),\n",
    "                \"revenue\": torch.tensor(0, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        df_idx = self.valid_ids[idx]\n",
    "        row = self.df.iloc[df_idx]\n",
    "        movie_id = str(int(row['id']))\n",
    "        revenue = np.log1p(row['revenue'])\n",
    "\n",
    "        def load_image(directory):\n",
    "            image = Image.open(os.path.join(directory, f\"{movie_id}.jpg\")).convert(\"RGB\")\n",
    "            return self.transform(image)\n",
    "\n",
    "        return {\n",
    "            \"poster\": load_image(self.poster_dir),\n",
    "            \"backdrop\": load_image(self.backdrop_dir),\n",
    "            \"thumbnail\": load_image(self.thumbnail_dir),\n",
    "            \"revenue\": torch.tensor(revenue, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "def get_resnet_backbone():\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in resnet.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in resnet.avgpool.parameters():\n",
    "        param.requires_grad = True\n",
    "    return nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "class FineTunedEnsemble(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.poster_net = get_resnet_backbone()\n",
    "        self.backdrop_net = get_resnet_backbone()\n",
    "        self.thumbnail_net = get_resnet_backbone()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2048*3, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, poster, backdrop, thumbnail):\n",
    "        p = self.poster_net(poster)\n",
    "        b = self.backdrop_net(backdrop)\n",
    "        t = self.thumbnail_net(thumbnail)\n",
    "\n",
    "        x = torch.cat([p.view(p.size(0), -1), b.view(b.size(0), -1), t.view(t.size(0), -1)], dim=1)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad2f81",
   "metadata": {},
   "source": [
    "## Preparing Data For Visuals Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84b0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "df_train = pd.read_csv(\"movie_data_train.csv\")\n",
    "df_test = pd.read_csv(\"movie_data_test.csv\")\n",
    "\n",
    "train_dataset = MultiImageDataset(df_train, \"poster_dataset\", \"backdrop_dataset\", \"thumbnail_dataset\", transform)\n",
    "test_dataset = MultiImageDataset(df_test, \"poster_dataset\", \"backdrop_dataset\", \"thumbnail_dataset\", transform)\n",
    "\n",
    "train_idx, val_idx = train_test_split(list(range(len(train_dataset))), test_size=0.2, random_state=42)\n",
    "train_subset = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "val_subset = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf946e1",
   "metadata": {},
   "source": [
    "## Get Predictions from Visuals Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3092adcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nigelpoh/Desktop/SUTD/Computational Data Science/project_github/proj_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nigelpoh/Desktop/SUTD/Computational Data Science/project_github/proj_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Loading Training Predictions: 100%|██████████| 175/175 [00:39<00:00,  4.39it/s]\n",
      "Loading Validation Predictions: 100%|██████████| 44/44 [00:09<00:00,  4.54it/s]\n",
      "Loading Test Predictions: 100%|██████████| 55/55 [00:12<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "model = FineTunedEnsemble().to(device)\n",
    "checkpoint = torch.load('models/best_ensemble_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "visuals_train_preds = []\n",
    "visuals_val_preds = []\n",
    "visuals_test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader, desc=\"Loading Training Predictions\"):\n",
    "        p = batch[\"poster\"].to(device)\n",
    "        b = batch[\"backdrop\"].to(device)\n",
    "        t = batch[\"thumbnail\"].to(device)\n",
    "        y = batch[\"revenue\"].to(device)\n",
    "        y_hat = model(p, b, t).squeeze()\n",
    "        visuals_train_preds.extend(y_hat.cpu().view(-1).tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Loading Validation Predictions\"):\n",
    "        p = batch[\"poster\"].to(device)\n",
    "        b = batch[\"backdrop\"].to(device)\n",
    "        t = batch[\"thumbnail\"].to(device)\n",
    "        y = batch[\"revenue\"].to(device)\n",
    "        y_hat = model(p, b, t).squeeze()\n",
    "        visuals_val_preds.extend(y_hat.cpu().view(-1).tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Loading Test Predictions\"):\n",
    "        p = batch[\"poster\"].to(device)\n",
    "        b = batch[\"backdrop\"].to(device)\n",
    "        t = batch[\"thumbnail\"].to(device)\n",
    "        y = batch[\"revenue\"].to(device)\n",
    "        y_hat = model(p, b, t).squeeze()\n",
    "        visuals_test_preds.extend(y_hat.cpu().view(-1).tolist())\n",
    "\n",
    "visuals_train_preds = np.expm1(visuals_train_preds)\n",
    "visuals_val_preds = np.expm1(visuals_val_preds)\n",
    "visuals_test_preds = np.expm1(visuals_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773a68f",
   "metadata": {},
   "source": [
    "## Setting Up Trailer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5adea36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_sort_key(filename):\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "            for text in re.split(r'(\\d+)', filename)]\n",
    "\n",
    "class MovieKeyframeDataset(Dataset):\n",
    "    def __init__(self, dataframe, frame_dir, image_processor, num_frames=8):\n",
    "        self.dataframe = dataframe\n",
    "        self.frame_dir = frame_dir\n",
    "        self.image_processor = image_processor\n",
    "        self.num_frames = num_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        trailer_id = row['trailer']\n",
    "        label = torch.tensor(row['log_revenue'], dtype=torch.float32)\n",
    "\n",
    "        frame_folder = os.path.join(self.frame_dir, str(trailer_id))\n",
    "\n",
    "        if not os.path.exists(frame_folder):\n",
    "\n",
    "            dummy_frames = torch.zeros((self.num_frames, 3, 224, 224))\n",
    "            return {\n",
    "                \"pixel_values\": dummy_frames,\n",
    "                \"labels\": label\n",
    "            }\n",
    "\n",
    "        frame_files = sorted([\n",
    "            f for f in os.listdir(frame_folder) if f.endswith(\".jpg\")\n",
    "        ], key=numerical_sort_key)\n",
    "\n",
    "        selected_frames = frame_files[3:self.num_frames+3]\n",
    "\n",
    "        frames = []\n",
    "        for fname in selected_frames:\n",
    "            img_path = os.path.join(frame_folder, fname)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            frames.append(np.array(img))\n",
    "\n",
    "        pixel_values = self.image_processor(frames, return_tensors=\"pt\")[\"pixel_values\"][0]\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"labels\": label             \n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "class TimeSformer(nn.Module):\n",
    "    def __init__(self, model_name=\"facebook/timesformer-base-finetuned-k400\"):\n",
    "        super().__init__()\n",
    "        self.backbone = TimesformerForVideoClassification.from_pretrained(model_name)\n",
    "\n",
    "        hidden_size = self.backbone.config.hidden_size \n",
    "\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values): \n",
    "        outputs = self.backbone(pixel_values)\n",
    "        return outputs.logits.view(-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab86d4ea",
   "metadata": {},
   "source": [
    "## Loading Data for Trailer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "addae257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('movie_data_train.csv')\n",
    "df_train['log_revenue'] = np.log1p(df_train['revenue'])\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = MovieKeyframeDataset(train_dataset, \"frames\", processor, num_frames=8)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "val_dataset = MovieKeyframeDataset(val_dataset, \"frames\", processor, num_frames=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "df_test = pd.read_csv('movie_data_test.csv')\n",
    "df_test['log_revenue'] = np.log1p(df_test['revenue'])\n",
    "test_dataset = MovieKeyframeDataset(df_test, \"frames\", processor, num_frames=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb5fda",
   "metadata": {},
   "source": [
    "## Get Predictions from Trailer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf3b74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Training Predictions: 100%|██████████| 2786/2786 [05:16<00:00,  8.80it/s]\n",
      "Loading Validation Predictions: 100%|██████████| 697/697 [01:19<00:00,  8.75it/s]\n",
      "Loading Test Predictions: 100%|██████████| 871/871 [01:48<00:00,  8.00it/s]\n"
     ]
    }
   ],
   "source": [
    "model = TimeSformer().to(device) \n",
    "checkpoint = torch.load('models/best_trailer_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "trailer_train_preds = []\n",
    "trailer_val_preds = []\n",
    "trailer_test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader, desc=\"Loading Training Predictions\"):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(pixel_values)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        trailer_train_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    for batch in tqdm(val_loader, desc=\"Loading Validation Predictions\"):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(pixel_values)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        trailer_val_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    for batch in tqdm(test_loader, desc=\"Loading Test Predictions\"):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(pixel_values)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        trailer_test_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "\n",
    "trailer_train_preds = np.expm1(trailer_train_preds)\n",
    "trailer_val_preds = np.expm1(trailer_val_preds)\n",
    "trailer_test_preds = np.expm1(trailer_test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c10f3",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Generic Features Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7e70d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     genre_Drama  genre_Romance  genre_Horror  genre_Thriller  genre_Action  \\\n",
      "0              0              0             0               0             0   \n",
      "1              0              0             0               1             0   \n",
      "2              0              1             0               0             0   \n",
      "3              0              0             0               0             0   \n",
      "4              0              0             0               0             0   \n",
      "..           ...            ...           ...             ...           ...   \n",
      "866            0              0             0               1             0   \n",
      "867            0              0             0               1             0   \n",
      "868            0              1             0               0             0   \n",
      "869            0              0             0               1             0   \n",
      "870            0              1             0               0             0   \n",
      "\n",
      "     genre_Adventure  genre_Science Fiction  genre_Crime  genre_Comedy  \\\n",
      "0                  1                      0            0             0   \n",
      "1                  0                      0            1             0   \n",
      "2                  0                      0            0             0   \n",
      "3                  0                      1            1             0   \n",
      "4                  0                      0            0             0   \n",
      "..               ...                    ...          ...           ...   \n",
      "866                0                      0            0             0   \n",
      "867                0                      0            1             0   \n",
      "868                0                      0            0             0   \n",
      "869                0                      1            0             0   \n",
      "870                0                      0            0             0   \n",
      "\n",
      "     genre_History  genre_War  genre_Mystery  genre_Fantasy  genre_Family  \\\n",
      "0                0          0              0              0             1   \n",
      "1                0          0              0              0             0   \n",
      "2                0          0              0              0             0   \n",
      "3                0          0              0              0             0   \n",
      "4                0          0              0              0             1   \n",
      "..             ...        ...            ...            ...           ...   \n",
      "866              0          0              1              0             0   \n",
      "867              0          0              0              0             0   \n",
      "868              0          0              0              0             0   \n",
      "869              0          0              1              0             0   \n",
      "870              0          0              0              0             0   \n",
      "\n",
      "     genre_Animation  genre_Western  genre_Music  genre_Documentary  \\\n",
      "0                  0              0            0                  0   \n",
      "1                  0              0            0                  0   \n",
      "2                  0              0            0                  0   \n",
      "3                  0              0            0                  0   \n",
      "4                  1              0            0                  0   \n",
      "..               ...            ...          ...                ...   \n",
      "866                0              0            0                  0   \n",
      "867                0              0            0                  0   \n",
      "868                0              0            0                  0   \n",
      "869                0              0            0                  0   \n",
      "870                0              0            0                  0   \n",
      "\n",
      "     genre_TV Movie  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n",
      "..              ...  \n",
      "866               0  \n",
      "867               0  \n",
      "868               0  \n",
      "869               0  \n",
      "870               0  \n",
      "\n",
      "[871 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('movie_data_train.csv')\n",
    "\n",
    "numerical_features = ['budget', 'runtime', 'viewCount', 'likeCount', 'favoriteCount', 'commentCount']\n",
    "\n",
    "df['release_month'] = pd.to_datetime(df['release_date']).dt.month\n",
    "\n",
    "df['genres_list'] = df['genres'].str.split(',')\n",
    "\n",
    "X_numeric = df[numerical_features + ['release_month']]\n",
    "y = df['revenue']\n",
    "\n",
    "genres_exploded = df['genres_list'].explode()\n",
    "unique_genres = genres_exploded.dropna().unique()\n",
    "\n",
    "for genre in unique_genres:\n",
    "    df[f'genre_{genre.strip()}'] = df['genres_list'].apply(\n",
    "        lambda x: 1 if x is not None and genre in [g.strip() for g in x] else 0\n",
    "    )\n",
    "\n",
    "genre_columns = [col for col in df.columns if col.startswith('genre_')]\n",
    "\n",
    "X_combined = pd.concat([X_numeric, df[genre_columns]], axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_val = imputer.transform(X_val)\n",
    "\n",
    "test_df = pd.read_csv('movie_data_test.csv')\n",
    "\n",
    "test_df['release_month'] = pd.to_datetime(test_df['release_date']).dt.month\n",
    "test_df['genres_list'] = test_df['genres'].str.split(',')\n",
    "\n",
    "X_test_numeric = test_df[numerical_features + ['release_month']]\n",
    "\n",
    "for genre in unique_genres:\n",
    "    test_df[f'genre_{genre.strip()}'] = test_df['genres_list'].apply(\n",
    "        lambda x: 1 if x is not None and genre in [g.strip() for g in x] else 0\n",
    "    )\n",
    "\n",
    "X_test = pd.concat([X_test_numeric, test_df[genre_columns]], axis=1)\n",
    "print(test_df[genre_columns])\n",
    "\n",
    "X_test = SimpleImputer(strategy='constant', fill_value=0).fit_transform(X_test)\n",
    "\n",
    "y_test = test_df['revenue']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12491d7",
   "metadata": {},
   "source": [
    "## Get Predictions from Generic Features Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b62aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.015,\n",
    "            max_leaves=10,\n",
    "            subsample=0.5,\n",
    "            colsample_bytree=0.6,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=42,\n",
    "            min_child_weight=40,\n",
    "            tree_method=\"hist\", \n",
    "            verbosity=0\n",
    "        )\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "generic_train_preds = model.predict(X_train)\n",
    "generic_val_preds = model.predict(X_val)\n",
    "generic_test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b18d7",
   "metadata": {},
   "source": [
    "## Preparing Data for Late Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10808419",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train_preds = title_train_preds.reshape(-1, 1)\n",
    "title_val_preds = title_val_preds.reshape(-1, 1)\n",
    "title_test_preds = title_test_preds.reshape(-1, 1)\n",
    "\n",
    "visuals_train_preds = visuals_train_preds.reshape(-1, 1)\n",
    "visuals_val_preds = visuals_val_preds.reshape(-1, 1)\n",
    "visuals_test_preds = visuals_test_preds.reshape(-1, 1)\n",
    "\n",
    "trailer_train_preds = trailer_train_preds.reshape(-1, 1)\n",
    "trailer_val_preds = trailer_val_preds.reshape(-1, 1)\n",
    "trailer_test_preds = trailer_test_preds.reshape(-1, 1)\n",
    "\n",
    "generic_train_preds = generic_train_preds.reshape(-1, 1)\n",
    "generic_val_preds = generic_val_preds.reshape(-1, 1)\n",
    "generic_test_preds = generic_test_preds.reshape(-1, 1)\n",
    "\n",
    "train_actuals = train_actuals.reshape(-1,1)\n",
    "val_actuals = val_actuals.reshape(-1,1)\n",
    "test_actuals = test_actuals.reshape(-1,1)\n",
    "\n",
    "train_actuals = torch.from_numpy(train_actuals).to(device)\n",
    "val_actuals = torch.from_numpy(val_actuals).to(device)\n",
    "test_actuals = torch.from_numpy(test_actuals).to(device)\n",
    "\n",
    "train_preds = np.concatenate([title_train_preds, visuals_train_preds, trailer_train_preds, generic_train_preds], axis=1)\n",
    "val_preds = np.concatenate([title_val_preds, visuals_val_preds, trailer_val_preds, generic_val_preds], axis=1)\n",
    "test_preds = np.concatenate([title_test_preds, visuals_test_preds, trailer_test_preds, generic_test_preds], axis=1)\n",
    "\n",
    "train_preds = torch.from_numpy(train_preds.astype(np.float32)).to(device)\n",
    "val_preds = torch.from_numpy(val_preds.astype(np.float32)).to(device)\n",
    "test_preds = torch.from_numpy(test_preds.astype(np.float32)).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d95873ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dims\n",
    "\n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(dims[i], dims[i + 1]),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "        layers.append(nn.Linear(dims[-1], input_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x)\n",
    "        weights = F.softmax(logits, dim=1)\n",
    "        return weights\n",
    "\n",
    "\n",
    "class GatingFusionEnsemble:\n",
    "    def __init__(self, lr=1e-3, epochs=100, logging=True):\n",
    "        self.gating_net = None\n",
    "        self.logging = logging\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        input_dim = X_train.shape[1]\n",
    "        self.gating_net = GatingNetwork(input_dim).to(X_train.device)\n",
    "        optimizer = torch.optim.Adam(self.gating_net.parameters(), lr=self.lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.gating_net.train()\n",
    "            optimizer.zero_grad()\n",
    "            weights = self.gating_net(X_train)\n",
    "            weighted_preds = torch.sum(X_train * weights, dim=1, keepdim=True)\n",
    "            loss = criterion(weighted_preds, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.gating_net.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_weights = self.gating_net(X_val)\n",
    "                    val_preds = torch.sum(X_val * val_weights, dim=1, keepdim=True)\n",
    "                    val_loss = criterion(val_preds, y_val)\n",
    "\n",
    "                    val_r2 = r2_score(y_val.cpu().numpy(), val_preds.cpu().numpy())\n",
    "\n",
    "                    if self.logging:\n",
    "                        print(f\"Epoch {epoch} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f} | Val R²: {val_r2:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.gating_net.eval()\n",
    "        with torch.no_grad():\n",
    "            weights = self.gating_net(X)\n",
    "            return torch.sum(X * weights, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e84dbdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 0.8651 | Val Loss: 0.7588 | Val R²: 0.4563\n",
      "Epoch 1 | Train Loss: 0.8650 | Val Loss: 0.7588 | Val R²: 0.4563\n",
      "Epoch 2 | Train Loss: 0.8650 | Val Loss: 0.7588 | Val R²: 0.4563\n",
      "Epoch 3 | Train Loss: 0.8649 | Val Loss: 0.7588 | Val R²: 0.4563\n",
      "Epoch 4 | Train Loss: 0.8648 | Val Loss: 0.7588 | Val R²: 0.4563\n",
      "Epoch 5 | Train Loss: 0.8647 | Val Loss: 0.7589 | Val R²: 0.4563\n",
      "Epoch 6 | Train Loss: 0.8646 | Val Loss: 0.7589 | Val R²: 0.4563\n",
      "Epoch 7 | Train Loss: 0.8646 | Val Loss: 0.7589 | Val R²: 0.4563\n",
      "Epoch 8 | Train Loss: 0.8645 | Val Loss: 0.7589 | Val R²: 0.4563\n",
      "Epoch 9 | Train Loss: 0.8644 | Val Loss: 0.7589 | Val R²: 0.4562\n",
      "Validation R²: 0.4562\n",
      "Test R²: 0.4085\n"
     ]
    }
   ],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_train = torch.tensor(X_scaler.fit_transform(train_preds.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_scaler.transform(val_preds.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = torch.tensor(y_scaler.fit_transform(train_actuals.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_scaler.transform(val_actuals.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "\n",
    "X_test = torch.tensor(X_scaler.transform(test_preds.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_scaler.transform(test_actuals.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "\n",
    "gated_ensemble = GatingFusionEnsemble(lr = 1e-5, epochs=10)\n",
    "gated_ensemble.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_pred = gated_ensemble.predict(X_val)\n",
    "    val_pred_np = val_pred.cpu().numpy()\n",
    "    val_actuals_np = y_val.cpu().numpy()\n",
    "    val_r2 = r2_score(val_actuals_np, val_pred_np)\n",
    "\n",
    "    test_pred = gated_ensemble.predict(X_test)\n",
    "    test_pred_np = test_pred.cpu().numpy()\n",
    "    test_actuals_np = y_test.cpu().numpy()\n",
    "    test_r2 = r2_score(test_actuals_np, test_pred_np)\n",
    "\n",
    "    print(f\"Validation R²: {val_r2:.4f}\")\n",
    "    print(f\"Test R²: {test_r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78f3963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': gated_ensemble.gating_net.state_dict(),\n",
    "    'X_scaler': X_scaler,\n",
    "    'y_scaler': y_scaler\n",
    "}, 'models/gating_ensemble.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f808d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation R²: 0.4562\n",
      "Test R²: 0.4085\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "checkpoint = torch.load('models/gating_ensemble.pt', map_location=device, weights_only=False)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "gating_ensemble = GatingFusionEnsemble()\n",
    "gating_ensemble.gating_net = GatingNetwork(input_dim=input_dim).to(device)\n",
    "gating_ensemble.gating_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "gating_ensemble.gating_net.eval()\n",
    "\n",
    "X_scaler = checkpoint['X_scaler']\n",
    "y_scaler = checkpoint['y_scaler']\n",
    "\n",
    "X_val_scaled = torch.tensor(X_scaler.transform(val_preds.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "X_test_scaled = torch.tensor(X_scaler.transform(test_preds.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "y_val_cpu = torch.tensor(y_scaler.transform(val_actuals.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "y_test_cpu = torch.tensor(y_scaler.transform(test_actuals.cpu().numpy()), dtype=torch.float32).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_pred = gating_ensemble.predict(X_val_scaled)\n",
    "    val_r2 = r2_score(y_val_cpu.numpy(), val_pred.numpy())\n",
    "\n",
    "    test_pred = gating_ensemble.predict(X_test_scaled)\n",
    "    test_r2 = r2_score(y_test_cpu.numpy(), test_pred.numpy())\n",
    "\n",
    "    print(f\"Validation R²: {val_r2:.4f}\")\n",
    "    print(f\"Test R²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d43a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
